{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual screening Dataset\n",
    "\n",
    "Here we run all other scoring functions on the Dataset2 - the virtual screening dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_dataset = pd.read_csv(\"../Datasets/virtual_screening_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reformat_path(path):\n",
    "    prefix = \"/home/anja/Documents/\"\n",
    "    new = \"../../\"\n",
    "    if not prefix in path: return path\n",
    "    res = path[len(prefix):]\n",
    "    return new+res\n",
    "\n",
    "\n",
    "vs_dataset[\"path\"] = vs_dataset[\"path\"].apply(reformat_path)\n",
    "vs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pppene_to_array(tmp):\n",
    "    tmp = tmp.replace(\"(\", \"\")\n",
    "    tmp = tmp.replace(\")\", \"\")\n",
    "    tmp = tmp.strip(\"[]\")\n",
    "    tmp = tmp.replace(\" \", \"\")\n",
    "    tmp = tmp.replace(\"\\n\", \",\")\n",
    "    return np.fromstring(tmp, dtype=float, sep=\", \").reshape(9,20)\n",
    "\n",
    "vs_dataset_feat = pd.read_csv(\"../Featurization/rosettaPPPEnergies_vsData.csv\")\n",
    "vs_dataset_feat[\"energies\"] = vs_dataset_feat[\"energies\"].apply(pppene_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_dataset_feat = vs_dataset_feat[[\"allele\", \"peptide\", \"binder\", \"ba\", \"energies\", \"total_energy\"]]\n",
    "vs_dataset_feat[\"path\"] = vs_dataset[\"path\"]\n",
    "vs_dataset_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score with 3pHLA-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../Experiment1 - train ref2015-score, standard-pHLA-score and 3pHLA-score/\"\n",
    "\n",
    "def get_energies(X):\n",
    "    ene = np.roll(X, 4, axis = 0)[:9,:19]\n",
    "    ene = np.roll(ene, -4, axis = 0)\n",
    "    ene = ene.reshape(9*19)\n",
    "    return ene\n",
    "\n",
    "def score_3pHLA(row):\n",
    "    print(row)\n",
    "    allele = row[\"allele\"]\n",
    "    feat = row[\"energies\"]\n",
    "\n",
    "    model_9n = root_dir+\"/final_REGRmodels/\"+allele+\"ppp.pkl\"\n",
    "\n",
    "    model_9 = pk.load(open(model_9n, 'rb'))\n",
    "    pred1 = model_9.predict([get_energies(feat)])[0]\n",
    "    return pred1\n",
    "\n",
    "alleles = vs_dataset_feat[\"allele\"].unique()\n",
    "\n",
    "vs_dataset_feat[\"3pHLA-score\"] = vs_dataset_feat.apply(score_3pHLA, axis=1)\n",
    "\n",
    "vs_dataset_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_dataset[\"3pHLA-score\"] = vs_dataset_feat[\"3pHLA-score\"]\n",
    "vs_dataset[[\"allele\", \"peptide\", \"ba\", \"binder\", \"path\", \"allele_type\", \"3pHLA-score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_dataset.to_csv(\"Results2_tmp_3phla.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score with Vina, Vinardo, AutoDock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HLA_Arena as arena\n",
    "# Initialize scoring\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def score_vvad(row, func):\n",
    "    print(row)\n",
    "    ene = arena.rescore_complex_simple_smina(row[\"path\"], func)\n",
    "    print(ene)\n",
    "    return ene\n",
    "    \n",
    "#to change scoring function instead of \"vina\", place \"vinardo\" or \"ad4_scoring\"\n",
    "funcs = [\"ad4_scoring\", \"vina\", \"vinardo\"]\n",
    "#funcs = [\"ad4_scoring\"]\n",
    "\n",
    "for f in funcs:\n",
    "    print(\"scoring with: \"+f)\n",
    "    vs_dataset_feat[f+\"-score\"] = vs_dataset_feat.apply(lambda x: score_vvad(x, f), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score with DOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeller import *\n",
    "from modeller.automodel import *\n",
    "from modeller.scripts import complete_pdb\n",
    "\n",
    "def score_dope(fpath):\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"SCORING WITH DOPE\")\n",
    "    print(fpath)\n",
    "    #score    \n",
    "    env = environ()\n",
    "    env.libs.topology.read(file='$(LIB)/top_heav.lib')\n",
    "    env.libs.parameters.read(file='$(LIB)/par.lib')\n",
    "    \n",
    "    mdl = complete_pdb(env, fpath)\n",
    "        \n",
    "    atmsel_lig = selection(mdl.chains[2])\n",
    "    atmsel_rec = selection(mdl.chains[0], mdl.chains[1])\n",
    "    atmsel_full = selection(mdl.chains[0], mdl.chains[1], mdl.chains[2])\n",
    "    try:\n",
    "        score_lig = atmsel_lig.assess_dope()\n",
    "        score_rec = atmsel_rec.assess_dope()\n",
    "        score_full = atmsel_full.assess_dope()\n",
    "    except:\n",
    "        print(\"Failed on: \"+fpath)\n",
    "        return (0, 0)\n",
    "    \n",
    "    score_diff = score_full - (score_rec + score_lig) \n",
    "    \n",
    "    return (score_full, score_diff)\n",
    "\n",
    "vs_dataset_feat[\"dope-score\"] = vs_dataset_feat.apply(lambda row: score_dope(row[\"path\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score with FoldX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def find_pHLA(file_path):\n",
    "    if not \"rdf_mount\" in file_path:\n",
    "        return file_path[file_path.rfind(\"/\")+1:file_path.find(\".pdb\")]\n",
    "    else:\n",
    "        prefix = \"../../rdf_mount/decoymulticonf/confs/\"\n",
    "        suffix = \"/full_system_confs\"\n",
    "        return file_path[file_path.find(prefix)+len(prefix):file_path.find(suffix)]\n",
    "    \n",
    "\n",
    "def score_FX(row):\n",
    "    print(\"processing \"+row[\"path\"])\n",
    "    #score    \n",
    "    env = environ()\n",
    "    env.libs.topology.read(file='$(LIB)/top_heav.lib')\n",
    "    env.libs.parameters.read(file='$(LIB)/par.lib')\n",
    "    \n",
    "    \n",
    "    mdl = complete_pdb(env, row[\"path\"])\n",
    "    chain_rec = mdl.chains[0].name\n",
    "    chain_pep = mdl.chains[2].name\n",
    "    \n",
    "    cname = find_pHLA(row[\"path\"])\n",
    "    command = \"./script_rescore_FoldX.sh \"+chain_pep+\" \"+chain_rec+\" \"+row[\"path\"]+\" \"+cname\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    process.wait()\n",
    "    ret = process.returncode\n",
    "    print(ret)\n",
    "    if not ret == 0: print(\"Error with execution\") \n",
    "    print(\"done with \"+row[\"path\"])\n",
    "    \n",
    "def reformat_path(path):\n",
    "    old = \"../../\"\n",
    "    new = \"/data/\"\n",
    "    if not old in path: return path\n",
    "    res = path[len(old):]\n",
    "    return new+res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = subprocess.Popen(\"touch FoldX_results.csv\", shell=True, stdout=subprocess.PIPE)\n",
    "process = subprocess.Popen(\"echo \\\"name, ene\\\" > FoldX_results.csv\", shell=True, stdout=subprocess.PIPE)\n",
    "process.wait()\n",
    "process.returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_dataset_feat[\"path\"] = vs_dataset_feat[\"path\"].apply(reformat_path)\n",
    "vs_dataset_feat.apply(lambda row: score_FX(row), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tmp = pd.read_csv(\"FoldX_results.csv\")\n",
    "res_tmp[\"foldx-score\"] = [\" ene\"].apply(lambda x: float(x))\n",
    "vs_dataset_feat[\"foldx-score\"] = res_tmp[\"foldx-score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score with GradDock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /graddock/GD/evaluate\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "## Access ligand/receptor files\n",
    "\n",
    "def extract_receptor_ligand(filename):\n",
    "    env = environ()\n",
    "    env.libs.topology.read(file='$(LIB)/top_heav.lib')\n",
    "    env.libs.parameters.read(file='$(LIB)/par.lib')\n",
    "    mdl = complete_pdb(env, filename)\n",
    "    \n",
    "    atmsel_lig = selection(mdl.chains[2])\n",
    "    atmsel_rec = selection(mdl.chains[0], mdl.chains[1])\n",
    "    \n",
    "    lig_name = filename[:filename.find(\".pdb\")]+\"_ligand.pdb\"\n",
    "    rec_name = filename[:filename.find(\".pdb\")]+\"_receptor.pdb\"\n",
    "    atmsel_lig.write(lig_name)\n",
    "    atmsel_rec.write(rec_name)\n",
    "    \n",
    "    return (lig_name, rec_name)\n",
    "    \n",
    "def get_rec_lig_name(path):\n",
    "    \n",
    "    if \"singleconf\" in path:\n",
    "        lname = lfname[lfname.rfind(\"/\")+1:]\n",
    "        rname = rfname[rfname.rfind(\"/\")+1:]\n",
    "        return ()\n",
    "    \n",
    "def score_GD(row):\n",
    "    print(\"processing \"+row[\"path\"])\n",
    "    (lfname, rfname) = extract_receptor_ligand(row[\"path\"])\n",
    "    folder_src = row[\"path\"][:row[\"path\"].rfind(\"/\")]\n",
    "    lname = lfname[lfname.rfind(\"/\")+1:]\n",
    "    rname = rfname[rfname.rfind(\"/\")+1:]\n",
    "    command = \"./GD_run.sh \"+lname+\" \"+rname+\" \"+folder_src+\" > GD_progress.txt\"\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    process.wait()\n",
    "    command = \"rm \"+lfname\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    process.wait()\n",
    "    command = \"rm \"+rfname\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    process.wait()\n",
    "    ret = process.returncode\n",
    "    print(ret)\n",
    "    if not ret == 0: print(\"Error with execution\") \n",
    "    print(\"done with \"+row[\"path\"])\n",
    "    \n",
    "def reformat_path(path):\n",
    "    old = \"../../\"\n",
    "    new = \"/data/\"\n",
    "    if not old in path: return path\n",
    "    res = path[len(old):]\n",
    "    return new+res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = subprocess.Popen(\"touch GD_results.csv\", shell=True, stdout=subprocess.PIPE)\n",
    "process = subprocess.Popen(\"echo \\\"name, complex, diff\\\" GD_results.csv\", shell=True, stdout=subprocess.PIPE)\n",
    "process.wait()\n",
    "process.returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"path\"] = dataset[\"path\"].apply(reformat_path)\n",
    "vs_dataset_feat.apply(lambda row: score_GD(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tmp = pd.read_csv(\"GD_results.csv\")\n",
    "res_tmp[\"graddock-score\"] = [\" diff\"].apply(lambda x: float(x))\n",
    "vs_dataset_feat[\"graddock-score\"] = res_tmp[\"graddock-score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_dataset_feat.to_csv(\"Results2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
