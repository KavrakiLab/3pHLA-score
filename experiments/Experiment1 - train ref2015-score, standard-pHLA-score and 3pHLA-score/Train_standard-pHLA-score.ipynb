{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning and training the models for standard-pHLA-score\n",
    "\n",
    "Input are the standard ref2015 features for complex, already generated in ../Featurization/rosettaComplexEnergies.csv\n",
    "\n",
    "We tune the parameters in the 5-fold-crossvalidation setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterSampler, cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "from scipy import stats\n",
    "import _pickle as cPickle\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the standard ref2015 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1 - load the energies\n",
    "def ene_to_array(ene_str):\n",
    "    ene_str = ene_str.strip(\"[]\")\n",
    "    ene_str = ene_str.strip(\"\\(\\)\")\n",
    "    return np.fromstring(ene_str, dtype=float, count = 20, sep=\", \")\n",
    "\n",
    "complex_ene = pd.read_csv(\"../Featurization/rosettaComplexEnergies.csv\")\n",
    "complex_ene = complex_ene[[\"allele\", \"peptide\", \"binder\", \"ba\", \"energies\", \"total_energy\"]]\n",
    "complex_ene[\"energies\"] = complex_ene[\"energies\"].apply(ene_to_array)\n",
    "complex_ene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the full dataset to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load split\n",
    "train_set = pd.read_csv(\"../Datasets/train_set.csv\")\n",
    "train_set = train_set[[\"allele\", \"peptide\", \"fileloc\", \"allele_type\", \"fold_num\"]]\n",
    "\n",
    "#Merge to form the training set\n",
    "train_dataset = pd.merge(complex_ene, train_set, on=[\"allele\", \"peptide\"], suffixes=[\"\", \"_y\"], how=\"inner\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features in training format\n",
    "# and get the cross-validation iterator\n",
    "def extract_features_Xy_cv(merged_df, allele):\n",
    "    allele_data = merged_df[merged_df[\"allele\"]==allele]\n",
    "    allele_data[\"enefeat\"] = allele_data[\"energies\"].apply(lambda x: x[:-1])\n",
    "    allele_data = allele_data.reset_index(drop=True)\n",
    "    flag = 0\n",
    "    for index, row in allele_data.iterrows():\n",
    "        if flag == 0:\n",
    "            X = np.array(row['enefeat'])\n",
    "            flag = 1\n",
    "        else: \n",
    "            X = np.vstack((X, row['enefeat']))\n",
    "    #extract binding energies        \n",
    "    y = np.array(list(allele_data[\"ba\"]))\n",
    "    y_l = np.array(list(allele_data[\"binder\"]))\n",
    "    \n",
    "    cv_iter = []\n",
    "    for split in range(5):\n",
    "        test_ind = allele_data.index[(allele_data['fold_num'] == split)].tolist()\n",
    "        train_ind = allele_data.index[~(allele_data['fold_num'] == split)].tolist()\n",
    "        cv_iter.append((train_ind, test_ind))\n",
    "        \n",
    "    return (X, y, y_l, cv_iter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def param_tune_allele(allele, train_dataset):\n",
    "    \n",
    "    allele_td = train_dataset[train_dataset[\"allele\"]==allele]\n",
    "    (X_train, y_train, y_l, cv) = extract_features_Xy_cv(allele_td, allele)\n",
    "    #shuffle for oob\n",
    "    X_train_s, y_train_s, y_l_s = shuffle(X_train, y_train, y_l, random_state=0)\n",
    "\n",
    "\n",
    "    grid_params = {'n_estimators': [x for x in range(100, 1100, 100)], \n",
    "            'max_depth': [x for x in range(10, 100, 10)], \n",
    "            'min_samples_leaf': [x for x in range(10, 100, 10)], \n",
    "            'bootstrap': [True],\n",
    "            'oob_score':[True],\n",
    "            'max_features':[\"auto\", \"sqrt\", \"log2\"]\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "    regr_oob = RandomForestRegressor(n_jobs=-1)\n",
    "    regr_cv = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "    best_oob_score = 0 \n",
    "    best_oob_params = None\n",
    "    best_cv_mscore = 0\n",
    "    best_cv_scores = None\n",
    "    best_cv_params = None\n",
    "    for i, g in enumerate(ParameterSampler(grid_params, n_iter=100)):\n",
    "        print(\"Parameter iteration: \"+str(i))\n",
    "        print(\"OOB\")\n",
    "        #out of bag\n",
    "        print(g)\n",
    "        regr_oob.set_params(**g)\n",
    "        regr_oob.fit(X_train_s,y_train_s)\n",
    "        print(regr_oob.oob_score_)\n",
    "        if regr_oob.oob_score_ > best_oob_score:\n",
    "            best_oob_params = g\n",
    "            best_oob_score = regr_oob.oob_score_\n",
    "        \n",
    "        print(\"CV\")\n",
    "        #cross-validation\n",
    "        regr_cv.set_params(**g)\n",
    "        cv_scores = cross_val_score(regr_cv, X_train, y_train, cv=cv, n_jobs = -1)\n",
    "        cv_mscore = statistics.mean(cv_scores)\n",
    "        print(cv_scores)\n",
    "        print(cv_mscore)\n",
    "        if cv_mscore > best_cv_mscore:\n",
    "            best_cv_params = g\n",
    "            best_cv_scores = cv_scores\n",
    "            best_cv_mscore = cv_mscore\n",
    "            \n",
    "    print(\"Best OOB \"+str(best_oob_score))\n",
    "    print(best_oob_params)\n",
    "    print(\"Best CV \"+str(best_cv_mscore))\n",
    "    print(best_cv_params)\n",
    "    return (best_oob_params, best_oob_score, best_cv_params, best_cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles = train_dataset[\"allele\"].unique()\n",
    "results = {\"allele\":[], \"best_oob_param\":[], \"best_oob_score\":[], \"best_cv_param\":[], \"best_cv_scores\":[]}\n",
    "\n",
    "for allele in alleles:\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"ALLELE\")\n",
    "    print(allele)\n",
    "    res = param_tune_allele(allele, train_dataset)\n",
    "    results[\"allele\"].append(allele)\n",
    "    results[\"best_oob_param\"].append(res[0])\n",
    "    results[\"best_oob_score\"].append(res[1])\n",
    "    results[\"best_cv_param\"].append(res[2])\n",
    "    results[\"best_cv_scores\"].append(res[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_pickle(\"crossval_complex.pkl\")\n",
    "results_df.to_csv(\"crossval_complex.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models with best parameters on the full training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model(allele, params, exp_name):\n",
    "    allele_train_dataset = train_dataset[train_dataset[\"allele\"]==allele]\n",
    "    (X_train, y_train, y_l, cv) = extract_features_Xy_cv(allele_train_dataset, allele)\n",
    "    regr_best = RandomForestRegressor(n_jobs=-1)\n",
    "    regr_best.set_params(**params)\n",
    "    regr_best.fit(X_train, y_train)\n",
    "    with open('./final_REGRmodels/'+allele+exp_name+'.pkl', 'wb') as fid:\n",
    "        cPickle.dump(regr_best, fid)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for allele in alleles:\n",
    "    params = list(results_df[results_df[\"allele\"]==allele][\"best_cv_param\"])[0]\n",
    "    train_best_model(allele, params, \"complex\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
